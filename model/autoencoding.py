# -*- coding: utf-8 -*-
"""Untitled33.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yl4-oyMU7yv4JysumwNM_Qs9JPchausC
"""

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

data = pd.read_csv("vibration data.csv")
df = data.dropna()
df_train = df[:1000] ##그냥 시간 적게 걸리라고 1000개로 train 과 test로 나눴음
df_test = df[1000:2000]

df_train_nor = df_train['Normal']
df_train_abnor = df_train['Abnormal']
df_test_nor = df_train['Normal']
df_test_abnor = df_train['Abnormal']

df_train_nor = pd.DataFrame(df_train_nor)
df_test_nor = pd.DataFrame(df_test_nor)
df_train_abnor = pd.DataFrame(df_train_abnor)
df_test_abnor = pd.DataFrame(df_test_abnor)

def build_model():
    model = keras.Sequential([
        layers.Dense(64, activation='sigmoid',input_shape=[len(df_train_nor.columns)]),
        layers.Dense(32, activation='sigmoid'),
        layers.Dense(100) # 여기 레이어 숫자들은 알아서 조절 가능 이게 아마 마지막이 1000이면 내가 넣은 인풋도 1000이니까 autoencoding 개념인듯?
    ])

    optimizer = tf.keras.optimizers.RMSprop(0.001)

    model.compile(loss='mse',optimizer='adam', metrics=['mae','mse']) # 학습률은 아담씨가 알아서 잘해줄꺼고 mae(절대평균오차), mse(평균제곱오차)를 구함 loss는 저번에 교수님이 mse라고 했던게 기억남..
    return model

model.predict(df_train_nor[:10]) # 그냥 값이 어쨰 나오는지

class PrintDot(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs):
        if epoch % 100 == 0: print('')
    print('.', end='')

model = build_model()
history = model.fit(df_train_nor, df_test_nor, epochs=10, validation_split = 0.2, verbose = 0, callbacks=[PrintDot()])

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist # 값들 확인해봐야지

import matplotlib.pyplot as plt

# 그래프로 epoch당 loss값 시각화

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure(figsize=(8,12))

  plt.subplot(2,1,1)
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error mae')
  plt.plot(hist['epoch'], hist['mae'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mae'],
           label = 'Val Error')
  plt.ylim([0,0.1])
  plt.legend()

  plt.subplot(2,1,2)
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error mse')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.ylim([0,0.05])
  plt.legend()
  plt.show()

plot_history(history)